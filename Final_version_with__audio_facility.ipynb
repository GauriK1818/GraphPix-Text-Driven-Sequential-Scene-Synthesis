{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPODr2ZjCmM5",
        "outputId": "689af598-cea5-461d-fe02-0ab5a39902ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (24.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.27.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install diffusers\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw9oCnhoCuXc",
        "outputId": "6ded39f0-7315-4a3d-c02c-6adf23d60bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.33.0 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtLH1pQlgeWt",
        "outputId": "a61b4ef7-7a76-4b89-b5f2-6f26265931cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gtts\n",
            "  Downloading gTTS-2.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
            "Installing collected packages: gtts\n",
            "Successfully installed gtts-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YamXIqY-CuZr",
        "outputId": "9a8b561d-59a6-483c-f969-85ebbb51a38d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import SemanticStableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import io\n",
        "import networkx as nx\n",
        "import spacy\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "wave_css = \"\"\"\n",
        ".stApp > header {\n",
        "    background-color: transparent;\n",
        "}\n",
        "\n",
        ".stApp {\n",
        "    background: linear-gradient(45deg,  #E7717D 40%, #FAEBD7 45%, #C2B9B0 55%, #91BAD6 10%);\n",
        "    animation: my_animation 20s ease infinite;\n",
        "    background-size: 200% 200%;\n",
        "    background-attachment: fixed;\n",
        "}\n",
        "\n",
        "@keyframes my_animation {\n",
        "    0% {background-position: 0% 0%;}\n",
        "    50% {background-position: 100% 100%;}\n",
        "    100% {background-position: 0% 0%;}\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return nlp(text)\n",
        "\n",
        "def text_to_prompts(text):\n",
        "    # Split the text into sentences using full stops as delimiters\n",
        "    sentences = text.split(\".\")\n",
        "\n",
        "    # Remove any empty strings resulting from consecutive full stops\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def find_adjective_noun_in_prompts(prompts):\n",
        "    all_adjective_noun_pairs = []\n",
        "    for prompt in prompts:\n",
        "        tokens = word_tokenize(prompt)\n",
        "        tagged_words = pos_tag(tokens)\n",
        "\n",
        "        adjective_noun_pairs = []\n",
        "        for i in range(len(tagged_words) - 1):\n",
        "            word, tag = tagged_words[i]\n",
        "            next_word, next_tag = tagged_words[i + 1]\n",
        "            if tag.startswith('JJ') and next_tag.startswith('NN'):\n",
        "                adjective_noun_pairs.append((word, next_word))\n",
        "\n",
        "        all_adjective_noun_pairs.extend(adjective_noun_pairs)\n",
        "    return all_adjective_noun_pairs\n",
        "\n",
        "def generate_scene_graph(text):\n",
        "    # Preprocess the text\n",
        "    doc = preprocess_text(text)\n",
        "\n",
        "    # Create a directed graph using NetworkX\n",
        "    graph = nx.DiGraph()\n",
        "\n",
        "    # Iterate through the tokens in the sentence\n",
        "    for token in doc:\n",
        "        # Add nodes for each token with POS tags\n",
        "        graph.add_node(token.text, pos=token.pos_)\n",
        "\n",
        "    # Add edges based on syntactic dependencies\n",
        "    for token in doc:\n",
        "        for child in token.children:\n",
        "            graph.add_edge(token.text, child.text, dep=token.dep_)\n",
        "\n",
        "    return graph\n",
        "\n",
        "def visualize_scene_graph(graph):\n",
        "    plt.figure()\n",
        "    # Visualize the scene graph using NetworkX\n",
        "    pos = nx.spring_layout(graph)\n",
        "\n",
        "    # Create labels with word and POS information\n",
        "    node_labels = {node: f\"{node}\\n{data['pos']}\" for node, data in graph.nodes(data=True)}\n",
        "\n",
        "    # Draw nodes with labels\n",
        "    nx.draw(graph, pos, with_labels=True, labels=node_labels, font_weight='bold',\n",
        "            node_color='skyblue', node_size=1500, font_size=7, edge_color='gray', linewidths=0.5)\n",
        "\n",
        "    # Save the plot to a buffer\n",
        "    buffer = io.BytesIO()\n",
        "    plt.savefig(buffer, format='png')  # Explicitly set the format to PNG\n",
        "    buffer.seek(0)\n",
        "\n",
        "    return buffer\n",
        "\n",
        "def text_to_speech(text, language='en'):\n",
        "    tts = gTTS(text=text, lang=language, slow=False)\n",
        "    audio_io = io.BytesIO()\n",
        "    tts.write_to_fp(audio_io)\n",
        "    audio_io.seek(0)\n",
        "    return audio_io.read()\n",
        "\n",
        "def main():\n",
        "    st.title(\"GraphPix: Sequential Scene Synthesis For Objects\")\n",
        "\n",
        "    st.markdown(f\"<style>{wave_css}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Text input box\n",
        "    text_input = st.text_area(\"Enter the text paragraph:\")\n",
        "\n",
        "    if st.button(\"Generate Images\"):\n",
        "        # Load the Diffusion Model pipeline\n",
        "        pipe = SemanticStableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device='cuda')\n",
        "\n",
        "        # Define the prompts\n",
        "        prompts = text_to_prompts(text_input)\n",
        "\n",
        "        # Find adjective-noun pairs in prompts\n",
        "        all_adjective_noun_pairs = find_adjective_noun_in_prompts(prompts)\n",
        "\n",
        "        # Construct editing prompts using adjective-noun pairs\n",
        "        editing_prompts = [\", \".join(pair) for pair in all_adjective_noun_pairs]\n",
        "\n",
        "        # Set up the generator\n",
        "        gen = torch.Generator(device='cuda')\n",
        "        gen.manual_seed(21)\n",
        "\n",
        "        # Generate images based on the prompts and editing prompts\n",
        "        images = []\n",
        "        scene_graphs = []\n",
        "        for prompt, editing_prompt in zip(prompts, editing_prompts):\n",
        "            try:\n",
        "                out = pipe(\n",
        "                    prompt=prompt,\n",
        "                    generator=gen,\n",
        "                    num_images_per_prompt=1,\n",
        "                    guidance_scale=7,\n",
        "                    editing_prompt=[editing_prompt],\n",
        "                    reverse_editing_direction=[False],\n",
        "                    edit_warmup_steps=[10],\n",
        "                    edit_guidance_scale=[4],\n",
        "                    edit_threshold=[0.99],\n",
        "                    edit_momentum_scale=0.3,\n",
        "                    edit_mom_beta=0.6,\n",
        "                    edit_weights=[1]\n",
        "                )\n",
        "                images.extend(out.images)\n",
        "\n",
        "                # Generate scene graph for the current prompt\n",
        "                scene_graph = generate_scene_graph(prompt)\n",
        "                scene_graphs.append(scene_graph)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error generating images: {e}\")\n",
        "\n",
        "        # Display all generated images with option to show scene graph\n",
        "        num_images = len(images)\n",
        "        st.text(f\"Number of generated images: {num_images}\")\n",
        "\n",
        "        for i, (image, scene_graph) in enumerate(zip(images, scene_graphs)):\n",
        "            st.image(image, caption=f\"Generated Image {i+1}\", use_column_width=True, width=400)\n",
        "\n",
        "            # Icon symbol next to each generated image\n",
        "            icon_expander = st.empty()\n",
        "            with icon_expander:\n",
        "                with st.expander(f\"Show Scene Graph {i+1}\", expanded=False):\n",
        "                    st.image(visualize_scene_graph(scene_graph), caption=\"Scene Graph\", use_column_width=True)\n",
        "        audio = text_to_speech(text_input)\n",
        "        st.audio(audio, format='audio/mpeg')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T5sErWRoCub-"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0NIL4bRUmxo",
        "outputId": "c8100523-7a22-44e4-e337-fde910cc6b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ0ztUPRUmz4",
        "outputId": "a3e95d58-0635-459d-8791-eac207f73b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken 2cM6tQosgyOMLeO5fgtuaayoTXJ_txjdzgiQnRspg5omXTfw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCusBobRUm3M",
        "outputId": "79e6cc5d-b2c4-41ca-a0d5-36e6c7ec15b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://aee1-104-197-52-190.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import streamlit as st\n",
        "\n",
        "# Get the port number where Streamlit is running\n",
        "port = st.get_option(\"server.port\")\n",
        "\n",
        "# Setup a tunnel to the streamlit port\n",
        "public_url = ngrok.connect(port)\n",
        "public_url"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}