{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPODr2ZjCmM5",
        "outputId": "2d616108-c30a-43f1-b701-443ba11844e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "!pip install diffusers\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw9oCnhoCuXc",
        "outputId": "6238db24-8429-4b31-8468-7a5f07a4af6c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.32.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.10.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.8.1b0)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from diffusers import SemanticStableDiffusionPipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import io\n",
        "import networkx as nx\n",
        "import spacy\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "wave_css = \"\"\"\n",
        ".stApp > header {\n",
        "    background-color: transparent;\n",
        "}\n",
        "\n",
        ".stApp {\n",
        "    background: linear-gradient(45deg,  #E7717D 40%, #FAEBD7 45%, #C2B9B0 55%, #91BAD6 10%);\n",
        "    animation: my_animation 20s ease infinite;\n",
        "    background-size: 200% 200%;\n",
        "    background-attachment: fixed;\n",
        "}\n",
        "\n",
        "@keyframes my_animation {\n",
        "    0% {background-position: 0% 0%;}\n",
        "    50% {background-position: 100% 100%;}\n",
        "    100% {background-position: 0% 0%;}\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return nlp(text)\n",
        "\n",
        "def text_to_prompts(text):\n",
        "    # Split the text into sentences using full stops as delimiters\n",
        "    sentences = text.split(\".\")\n",
        "\n",
        "    # Remove any empty strings resulting from consecutive full stops\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def find_adjective_noun_in_prompts(prompts):\n",
        "    all_adjective_noun_pairs = []\n",
        "    for prompt in prompts:\n",
        "        tokens = word_tokenize(prompt)\n",
        "        tagged_words = pos_tag(tokens)\n",
        "\n",
        "        adjective_noun_pairs = []\n",
        "        for i in range(len(tagged_words) - 1):\n",
        "            word, tag = tagged_words[i]\n",
        "            next_word, next_tag = tagged_words[i + 1]\n",
        "            if tag.startswith('JJ') and next_tag.startswith('NN'):\n",
        "                adjective_noun_pairs.append((word, next_word))\n",
        "\n",
        "        all_adjective_noun_pairs.extend(adjective_noun_pairs)\n",
        "    return all_adjective_noun_pairs\n",
        "\n",
        "def generate_scene_graph(text):\n",
        "    # Preprocess the text\n",
        "    doc = preprocess_text(text)\n",
        "\n",
        "    # Create a directed graph using NetworkX\n",
        "    graph = nx.DiGraph()\n",
        "\n",
        "    # Iterate through the tokens in the sentence\n",
        "    for token in doc:\n",
        "        # Add nodes for each token with POS tags\n",
        "        graph.add_node(token.text, pos=token.pos_)\n",
        "\n",
        "    # Add edges based on syntactic dependencies\n",
        "    for token in doc:\n",
        "        for child in token.children:\n",
        "            graph.add_edge(token.text, child.text, dep=token.dep_)\n",
        "\n",
        "    return graph\n",
        "\n",
        "def visualize_scene_graph(graph):\n",
        "    plt.figure()\n",
        "    # Visualize the scene graph using NetworkX\n",
        "    pos = nx.spring_layout(graph)\n",
        "\n",
        "    # Create labels with word and POS information\n",
        "    node_labels = {node: f\"{node}\\n{data['pos']}\" for node, data in graph.nodes(data=True)}\n",
        "\n",
        "    # Draw nodes with labels\n",
        "    nx.draw(graph, pos, with_labels=True, labels=node_labels, font_weight='bold',\n",
        "            node_color='skyblue', node_size=1500, font_size=7, edge_color='gray', linewidths=0.5)\n",
        "\n",
        "    # Save the plot to a buffer\n",
        "    buffer = io.BytesIO()\n",
        "    plt.savefig(buffer, format='png')  # Explicitly set the format to PNG\n",
        "    buffer.seek(0)\n",
        "\n",
        "    return buffer\n",
        "\n",
        "def main():\n",
        "    st.title(\"GraphPix: Sequential Scene Synthesis For Objects\")\n",
        "\n",
        "    st.markdown(f\"<style>{wave_css}</style>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Text input box\n",
        "    text_input = st.text_area(\"Enter the text paragraph:\")\n",
        "\n",
        "    if st.button(\"Generate Images\"):\n",
        "        # Load the Diffusion Model pipeline\n",
        "        pipe = SemanticStableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(device='cuda')\n",
        "\n",
        "        # Define the prompts\n",
        "        prompts = text_to_prompts(text_input)\n",
        "\n",
        "        # Find adjective-noun pairs in prompts\n",
        "        all_adjective_noun_pairs = find_adjective_noun_in_prompts(prompts)\n",
        "\n",
        "        # Construct editing prompts using adjective-noun pairs\n",
        "        editing_prompts = [\", \".join(pair) for pair in all_adjective_noun_pairs]\n",
        "\n",
        "        # Set up the generator\n",
        "        gen = torch.Generator(device='cuda')\n",
        "        gen.manual_seed(21)\n",
        "\n",
        "        # Generate images based on the prompts and editing prompts\n",
        "        images = []\n",
        "        scene_graphs = []\n",
        "        for prompt, editing_prompt in zip(prompts, editing_prompts):\n",
        "            try:\n",
        "                out = pipe(\n",
        "                    prompt=prompt,\n",
        "                    generator=gen,\n",
        "                    num_images_per_prompt=1,\n",
        "                    guidance_scale=7,\n",
        "                    editing_prompt=[editing_prompt],\n",
        "                    reverse_editing_direction=[False],\n",
        "                    edit_warmup_steps=[10],\n",
        "                    edit_guidance_scale=[4],\n",
        "                    edit_threshold=[0.99],\n",
        "                    edit_momentum_scale=0.3,\n",
        "                    edit_mom_beta=0.6,\n",
        "                    edit_weights=[1]\n",
        "                )\n",
        "                images.extend(out.images)\n",
        "\n",
        "                # Generate scene graph for the current prompt\n",
        "                scene_graph = generate_scene_graph(prompt)\n",
        "                scene_graphs.append(scene_graph)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error generating images: {e}\")\n",
        "\n",
        "        # Display all generated images with option to show scene graph\n",
        "        num_images = len(images)\n",
        "        st.text(f\"Number of generated images: {num_images}\")\n",
        "\n",
        "        for i, (image, scene_graph) in enumerate(zip(images, scene_graphs)):\n",
        "            st.image(image, caption=f\"Generated Image {i+1}\", use_column_width=True, width=400)\n",
        "\n",
        "            # Icon symbol next to each generated image\n",
        "            icon_expander = st.empty()\n",
        "            with icon_expander:\n",
        "                with st.expander(f\"Show Scene Graph {i+1}\", expanded=False):\n",
        "                    st.image(visualize_scene_graph(scene_graph), caption=\"Scene Graph\", use_column_width=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YamXIqY-CuZr",
        "outputId": "9b87d9a3-7ae6-42ab-d97c-d7b64ec36ddf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "T5sErWRoCub-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0NIL4bRUmxo",
        "outputId": "5e6e450d-bcab-4d1c-fc25-238f9143c6b6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2cM6tQosgyOMLeO5fgtuaayoTXJ_txjdzgiQnRspg5omXTfw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ0ztUPRUmz4",
        "outputId": "67c6fcac-8cc1-427d-876d-3ca8c6eb16c6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import streamlit as st\n",
        "\n",
        "# Get the port number where Streamlit is running\n",
        "port = st.get_option(\"server.port\")\n",
        "\n",
        "# Setup a tunnel to the streamlit port\n",
        "public_url = ngrok.connect(port)\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCusBobRUm3M",
        "outputId": "3463f59e-0c4a-4381-9d09-fa763ed5afa6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://9613-35-239-246-11.ngrok-free.app\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}